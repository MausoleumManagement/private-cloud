apiVersion: controlplane.cluster.x-k8s.io/v1beta2
kind: KubeadmControlPlane
metadata:
  annotations:
  labels:
    cluster.x-k8s.io/cluster-name: nekropolis
  name: nekropolis-control-plane
spec:
  kubeadmConfigSpec:
    format: cloud-config
    initConfiguration:
      patches:
        directory: /etc/kubernetes/patches
      nodeRegistration:
        imagePullPolicy: IfNotPresent
        kubeletExtraArgs:
          - name: provider-id
            value: "proxmox://'{{ ds.meta_data.instance_id }}'"
    joinConfiguration:
      patches:
        directory: /etc/kubernetes/patches
      nodeRegistration:
        imagePullPolicy: IfNotPresent
        kubeletExtraArgs:
          - name: provider-id
            value: "proxmox://'{{ ds.meta_data.instance_id }}'"
    clusterConfiguration:
      apiServer:
        extraArgs:
          - name: enable-admission-plugins
            value: "NamespaceExists"
    preKubeadmCommands:
      - /etc/kube-vip-prepare.sh
    users:
      - name: root
        sshAuthorizedKeys:
          - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIJeA+KvPI+y/OtbCkWpKTt9bpGKXkDtwZX3pdjzeRuRD
            Leon Welchert privat
    files:
      # by default, the kubelet uses a certificate with its hostname as subject
      # that makes the metrics server sad, because it accesses them via IP
      # we patch the kubelet config so the kubelets ask for certificates
      # which the metrics server can actually use to talk to the kubelets via TLS
      # https://kubernetes.io/docs/reference/access-authn-authz/kubelet-tls-bootstrapping/
      # https://www.zeng.dev/post/2023-kubeadm-enable-kubelet-serving-certs/
      # https://cluster-api.sigs.k8s.io/tasks/bootstrap/kubeadm-bootstrap/kubelet-config#use-kubeadms-kubeletconfiguration-patch-target
      - path: /etc/kubernetes/patches/kubeletconfiguration0+strategic.json
        owner: "root:root"
        permissions: "0600"
        content: |
          {
            "apiVersion": "kubelet.config.k8s.io/v1beta1",
            "kind": "KubeletConfiguration",
            "serverTLSBootstrap": true
          }
      # See here on how to generate the kube-vip  manifest
      # https://kube-vip.io/docs/installation/static/#generating-a-manifest
      - content: |-
          apiVersion: v1
          kind: Pod
          metadata:
            creationTimestamp: null
            name: kube-vip
            namespace: kube-system
          spec:
            containers:
            - args:
              - manager
              env:
              - name: vip_arp
                value: "true"
              - name: port
                value: "6443"
              - name: vip_nodename
                valueFrom:
                  fieldRef:
                    fieldPath: spec.nodeName
              - name: vip_subnet
                value: "32"
              - name: dns_mode
                value: first
              - name: cp_enable
                value: "true"
              - name: cp_namespace
                value: kube-system
              - name: svc_enable
                value: "true"
              - name: svc_leasename
                value: plndr-svcs-lock
              - name: svc_election
                value: "true"
              - name: vip_leaderelection
                value: "true"
              - name: vip_leasename
                value: plndr-cp-lock
              - name: vip_leaseduration
                value: "5"
              - name: vip_renewdeadline
                value: "3"
              - name: vip_retryperiod
                value: "1"
              - name: address
                value: 192.168.10.11
              - name: prometheus_server
                value: :2112
              image: ghcr.io/kube-vip/kube-vip:v0.9.2
              imagePullPolicy: IfNotPresent
              name: kube-vip
              resources: {}
              securityContext:
                capabilities:
                  add:
                  - NET_ADMIN
                  - NET_RAW
                  drop:
                  - ALL
              volumeMounts:
              - mountPath: /etc/kubernetes/admin.conf
                name: kubeconfig
            hostAliases:
            - hostnames:
              - kubernetes
              ip: 127.0.0.1
            hostNetwork: true
            volumes:
            - hostPath:
                path: /etc/kubernetes/admin.conf
              name: kubeconfig
          status: {}

        owner: root:root
        path: /etc/kubernetes/manifests/kube-vip.yaml
      - content: |-
          #!/bin/bash

          # Copyright 2020 The Kubernetes Authors.
          #
          # Licensed under the Apache License, Version 2.0 (the "License");
          # you may not use this file except in compliance with the License.
          # You may obtain a copy of the License at
          #
          #     http://www.apache.org/licenses/LICENSE-2.0
          #
          # Unless required by applicable law or agreed to in writing, software
          # distributed under the License is distributed on an "AS IS" BASIS,
          # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
          # See the License for the specific language governing permissions and
          # limitations under the License.

          set -e

          # Configure the workaround required for kubeadm init with kube-vip:
          # xref: https://github.com/kube-vip/kube-vip/issues/684

          # Nothing to do for kubernetes < v1.29
          KUBEADM_MINOR="$(kubeadm version -o short | cut -d '.' -f 2)"
          if [[ "$KUBEADM_MINOR" -lt "29" ]]; then
            exit 0
          fi

          IS_KUBEADM_INIT="false"

          # cloud-init kubeadm init
          if [[ -f /run/kubeadm/kubeadm.yaml ]]; then
            IS_KUBEADM_INIT="true"
          fi

          # ignition kubeadm init
          if [[ -f /etc/kubeadm.sh ]] && grep -q -e "kubeadm init" /etc/kubeadm.sh; then
            IS_KUBEADM_INIT="true"
          fi

          if [[ "$IS_KUBEADM_INIT" == "true" ]]; then
            sed -i 's#path: /etc/kubernetes/admin.conf#path: /etc/kubernetes/super-admin.conf#' \
              /etc/kubernetes/manifests/kube-vip.yaml
          fi
        owner: root:root
        path: /etc/kube-vip-prepare.sh
        permissions: '0700'
  machineTemplate:
    spec:
      infrastructureRef:
        apiGroup: infrastructure.cluster.x-k8s.io
        kind: ProxmoxMachineTemplate
        # the german numeral suffix at the end is used to differentiate machine templates
        # within the same kubernetes release, since they should not be modified
        # see https://cluster-api.sigs.k8s.io/tasks/updating-machine-templates.html
        name: nekropolis-control-plane-1.33.7-eins
  replicas: 3
  rollout:
    strategy:
      rollingUpdate:
        maxSurge: 1
      type: RollingUpdate
  version: v1.33.7
